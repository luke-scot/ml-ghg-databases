{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "import sklearn.linear_model\n",
    "\n",
    "\"\"\"Define graph forming functions\"\"\"\n",
    "# Import packages\n",
    "\n",
    "import joblib\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "from sklearn import tree\n",
    "import sklearn.svm as svm\n",
    "from sklearn import ensemble\n",
    "import sklearn.metrics as skm\n",
    "import sklearn.preprocessing as pp\n",
    "import sklearn.linear_model as lms\n",
    "import sklearn.neural_network as skl_nn\n",
    "import sklearn.neighbors as neighbors\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import sklearn.model_selection as model_sel\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch_sparse\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Input data\n",
    "random_state = 2\n",
    "np.random.seed(random_state)\n",
    "data_path = \"C:/Users\\lukec\\PycharmProjects\\emissions-tracking-conda\\emissions-tracking\\data\\classification_inputs/\"\n",
    "\n",
    "max_test_set = 100000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def filter_for_start_yr(df, start_col, end_col) -> pd.DataFrame:\n",
    "    \"\"\"Convert dataframe of plants with entry for each year into dataframe with row for each year\"\"\"\n",
    "    # Get rid of emissions for years before start year\n",
    "    df['Age'] = df['Year'].astype(int) - df[start_col].astype(int)\n",
    "    df = df[df['Age'] >= 0]\n",
    "\n",
    "    # Get rid of emissions for years after end years\n",
    "    df['ToGo'] = df[end_col].astype(int) - df['Year'].astype(int)\n",
    "    df = df[df['ToGo'] >= 0]\n",
    "\n",
    "    df[['START_YR', 'END_YR']] = df[['START_YR', 'END_YR']].astype(int)\n",
    "\n",
    "    return df.drop(columns=['ToGo'])\n",
    "\n",
    "def pivot_data_dfs(df:pd.DataFrame, time_col) -> [pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Pivot data dataframes to get each entry and all year/month values in rows\"\"\"\n",
    "    feature_cols = [i for i in df.columns if i not in [time_col, 'Emissions']]\n",
    "    df_pivoted = df.pivot(index=feature_cols,\n",
    "                          columns=time_col,\n",
    "                          values = 'Emissions').reset_index()\n",
    "    return df_pivoted, feature_cols\n",
    "\n",
    "\n",
    "def melt_data_dfs(df:pd.DataFrame, feature_cols, time_col) -> pd.DataFrame:\n",
    "    \"\"\"Melt data dataframes to get row per date entry for each facility\"\"\"\n",
    "    melted = df.melt(id_vars=feature_cols, var_name=time_col, value_name='Emissions').dropna(subset=['Emissions'])\n",
    "    melted[time_col] = melted[time_col].astype(int)\n",
    "    \n",
    "    if 'START_YR' in df.columns and 'END_YR' in df.columns:\n",
    "        melted = filter_for_start_yr(melted, 'START_YR', 'END_YR')\n",
    "\n",
    "    return melted\n",
    "\n",
    "## Convert train and test sets into ML ready sets\n",
    "def series_to_bins(series:pd.Series, bins:list=None, labels:list=None, positive:bool=True):\n",
    "    # Convert a continuous pandas dataframe column into discrete bins\n",
    "    if bins is None:\n",
    "        bin_series = series[series!=0] if positive else series\n",
    "        bins = [min(bin_series.min(),0)-0.01, bin_series.quantile(0.25), bin_series.quantile(0.5), bin_series.quantile(0.75), bin_series.max()+0.01]\n",
    "    if labels is None: labels = list(range(len(bins)-1))\n",
    "\n",
    "    transformer = pp.FunctionTransformer(\n",
    "        pd.cut, kw_args={'bins': bins, 'labels': labels, 'retbins': False}\n",
    "    )\n",
    "    return bins, transformer.fit_transform(series)\n",
    "\n",
    "\n",
    "def preprocess_yearly(train_set, test_set, y_col='Emissions'):\n",
    "    \"\"\"Digitise train and test sets\"\"\"\n",
    "\n",
    "    # Create Y\n",
    "    bins, y_train_clf = series_to_bins(train_set[y_col])\n",
    "    _, y_test_clf = series_to_bins(test_set[y_col], bins=[test_set[y_col].min()-0.01]+bins[1:-1]+[test_set[y_col].max()+0.01])\n",
    "\n",
    "    y_train_reg, y_test_reg = train_set[y_col], test_set[y_col]\n",
    "    train_set, test_set = train_set.drop(columns=[y_col]), test_set.drop(columns=[y_col])\n",
    "\n",
    "    # Create X\n",
    "    # Deal with string columns\n",
    "    x_enc = pp.OrdinalEncoder()\n",
    "    string_cols = list(train_set.select_dtypes(include='object').columns)\n",
    "    train_set[string_cols] = train_set[string_cols].astype(str)\n",
    "    test_set[string_cols] = test_set[string_cols].astype(str)\n",
    "    x_strings = pd.concat((train_set[string_cols], test_set[string_cols]))\n",
    "    x_enc.fit(x_strings)\n",
    "\n",
    "    # Make float columns into int columns\n",
    "    float_cols = list(train_set.select_dtypes(include='float').columns)\n",
    "    train_set[float_cols], test_set[float_cols] = train_set[float_cols].astype(int), test_set[float_cols].astype(int)\n",
    "\n",
    "    if 'LATITUDE' in list(train_set.columns) and 'LONGITUDE' in list(train_set.columns):\n",
    "        train_set[['LATITUDE', 'LONGITUDE']] = (train_set[['LATITUDE', 'LONGITUDE']].astype(int)+[90, 180])\n",
    "        test_set[['LATITUDE', 'LONGITUDE']] = (test_set[['LATITUDE', 'LONGITUDE']].astype(int)+[90, 180])\n",
    "\n",
    "    int_cols = list(train_set.select_dtypes(include='integer').columns)\n",
    "    x_ints_min = pd.concat((train_set[int_cols], test_set[int_cols])).min().values\n",
    "    x_ints_train = train_set[int_cols] - x_ints_min\n",
    "    x_ints_test = test_set[int_cols] - x_ints_min\n",
    "\n",
    "    X_train = np.concatenate((x_enc.transform(train_set[string_cols]),\n",
    "                              x_ints_train.values), axis=1)\n",
    "    X_test = np.concatenate((x_enc.transform(test_set[string_cols]),\n",
    "                              x_ints_test.values), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    return X_train, X_test, y_train_clf, y_test_clf, y_train_reg, y_test_reg, x_enc\n",
    "\n",
    "def save_decoded_X(X, x_enc, cols, used, name):\n",
    "    min_years = [used['START_YR'].astype(int).min(), 1978]\n",
    "    X_inv = np.concatenate((x_enc.inverse_transform(X[:,:-4]), (X[:,-4:-2]+min_years).astype(int), X[:,-2:]), axis=1)\n",
    "    pd.DataFrame(X_inv, columns=list(columns[:-2]+['Year']+columns[-2:])).to_csv(name+'.csv')\n",
    "\n",
    "# Function to split rows into two DataFrames\n",
    "def split_rows(group, test_fraction):\n",
    "\n",
    "    num_rows = group.shape[0]\n",
    "    if num_rows == 1:\n",
    "        return None, None  # Exclude groups with only one sample\n",
    "\n",
    "    num_sampled_rows = int(min(max(test_fraction * num_rows, 1), num_rows-1))  # At least one sample for each group\n",
    "\n",
    "    test_df = group.sample(n=num_sampled_rows)\n",
    "    train_df = group.drop(test_df.index)\n",
    "\n",
    "    return train_df, test_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def create_yearly_data(data, input_data, gap_filling_level, timesteps, test_size):\n",
    "\n",
    "    if gap_filling_level == 1:\n",
    "        \"\"\"Gap filling level 1\n",
    "        Divide training data points (year for particular facility) from test data points -> Unknown year fill\"\"\"\n",
    "\n",
    "        train_set, test_set = data.copy(), data.copy()\n",
    "\n",
    "        # Calculate the number of entries to mask in each row\n",
    "        num_entries = data[timesteps].shape[1]\n",
    "        num_masked_entries = int(test_size * num_entries)\n",
    "\n",
    "        # Mask and unmask entries in each row\n",
    "        mask = np.zeros(data[timesteps].shape, dtype=bool)\n",
    "        for i in range(data[timesteps].shape[0]):\n",
    "            indices = np.random.choice(num_entries, size=num_masked_entries, replace=False)\n",
    "            mask[i, indices] = True\n",
    "\n",
    "        train_set[timesteps] = train_set[timesteps].mask(mask)\n",
    "        test_set[timesteps] = test_set[timesteps].mask(~mask)\n",
    "\n",
    "        feature_cols = [i for i in train_set.columns if i not in timesteps]\n",
    "        train_yearly, test_yearly = melt_data_dfs(train_set, feature_cols, time_col), melt_data_dfs(test_set, feature_cols, time_col)\n",
    "\n",
    "    elif gap_filling_level == 2:\n",
    "        \"\"\"Gap filling level 2\n",
    "        Divide training plants from test plants -> Unknown plant fill\"\"\"\n",
    "\n",
    "        grouping_cols = inference_cols if len(inference_cols) > 2 else [inference_cols[0]]\n",
    "\n",
    "        split_rows_partial = partial(split_rows, test_fraction=test_size)\n",
    "        grouped_df = data.groupby(grouping_cols)\n",
    "\n",
    "        train_dfs, test_dfs = zip(*grouped_df.apply(split_rows_partial))\n",
    "        train_set, test_set = pd.concat(train_dfs), pd.concat(test_dfs)\n",
    "\n",
    "        feature_cols = [i for i in train_set.columns if i not in timesteps]\n",
    "        train_yearly, test_yearly = melt_data_dfs(train_set, feature_cols, time_col), melt_data_dfs(test_set, feature_cols, time_col)\n",
    "\n",
    "    elif gap_filling_level == 3:\n",
    "        \"\"\"Gap filling level 3\n",
    "        Divide training countries or products from test countries or products -> Unknown country/product fill\"\"\"\n",
    "        gap3cols = [i for i in inference_cols if i!=divider]\n",
    "\n",
    "        split_rows_partial = partial(split_rows, test_fraction=test_size)\n",
    "        grouped_df = data.groupby(gap3cols)\n",
    "\n",
    "        train_dfs, test_dfs = zip(*grouped_df.apply(split_rows_partial))\n",
    "        train_set, test_set = pd.concat(train_dfs), pd.concat(test_dfs)\n",
    "        # train_set = data.groupby(gap3cols).apply(lambda x: x.sample(frac=1-test_size)).reset_index(drop=True)\n",
    "        # test_set = data.groupby(gap3cols).apply(lambda x: x.sample(frac=test_size)).reset_index(drop=True)\n",
    "\n",
    "        # train_divs, test_divs = model_sel.train_test_split(data[divider].unique(), test_size=0.3, random_state=1)\n",
    "        # train_set, test_set = [data[[i in divs for i in data[divider]]] for divs in [train_divs, test_divs]]\n",
    "\n",
    "        feature_cols = [i for i in train_set.columns if i not in timesteps]\n",
    "        train_yearly, test_yearly = melt_data_dfs(train_set, feature_cols, time_col), melt_data_dfs(test_set, feature_cols, time_col)\n",
    "\n",
    "    else: print('Please choose a gap filling level.')\n",
    "\n",
    "    return feature_cols, train_yearly, test_yearly"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def custom_interpolate(row):\n",
    "    if row.count() >= 3:  # Check if there are enough values for polynomial interpolation\n",
    "        return row.interpolate(method='polynomial', order=order, limit_direction='both')\n",
    "    else:\n",
    "        return row.interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "def metrics(y_true, y_pred, model_type='clf'):\n",
    "    if model_type == 'clf':\n",
    "        metric_dict = {'confusion': skm.confusion_matrix(y_true, y_pred),\n",
    "                       'overall_acc': skm.accuracy_score(y_true, y_pred),\n",
    "                       'average_acc': skm.balanced_accuracy_score(y_true, y_pred),\n",
    "                       'kappa': skm.cohen_kappa_score(y_true, y_pred),\n",
    "                       'IoU': skm.jaccard_score(y_true, y_pred, average='weighted')}\n",
    "    elif model_type == 'reg':\n",
    "        metric_dict = {'r2': skm.r2_score(y_true, y_pred),\n",
    "                       'mae': skm.mean_absolute_error(y_true, y_pred),\n",
    "                       'mse': skm.mean_squared_error(y_true, y_pred)}\n",
    "\n",
    "    else: raise 'Incorrect model type'\n",
    "\n",
    "    return metric_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def gap_interpolation(train_yearly:pd.DataFrame, test_yearly:pd.DataFrame, years:list, feature_cols:list, inference_cols:list, gap_filling_level:int, interpolation:str='linear', order:int=None, divider:str=None):\n",
    "    # Interpolate missing values in data rows of training set\n",
    "    df_train = train_yearly.pivot(index=feature_cols, columns=time_col, values='Emissions').reset_index()\n",
    "\n",
    "    if gap_filling_level == 1:\n",
    "        if order is not None:\n",
    "            train_years = df_train[years]\n",
    "            train_years.columns = train_years.columns.astype(int)\n",
    "            # sufficient = train_years[train_years.count(axis=1) > order+1]\n",
    "            # insufficient = train_years[train_years.count(axis=1) <= order+1]\n",
    "            df_train[years] = train_years.transpose().apply(custom_interpolate).transpose()\n",
    "                #pd.concat((sufficient.interpolate(method='polynomial', order=order, axis=1, limit_direction='both'),\n",
    "                                       #  insufficient.interpolate(method='linear', axis=1, limit_direction='both'))).sort_index()\n",
    "\n",
    "        else: df_train[years] = df_train[years].interpolate(method=model, order=order, axis=1, limit_direction='both')\n",
    "        df_train[years] = df_train[years].interpolate(method='pad', axis=1).interpolate(method='bfill', axis=1)\n",
    "        pred_yearly = melt_data_dfs(df_train, feature_cols, time_col)\n",
    "        inference_cols = feature_cols\n",
    "\n",
    "    else:\n",
    "        if gap_filling_level == 3 or inference_cols == feature_cols:\n",
    "            inference_cols = [item for item in inference_cols if item != divider]\n",
    "        # interp = train_yearly[inference_cols+years].groupby(inference_cols).mean()\n",
    "        #\n",
    "        # pred_yearly = pd.melt(interp.reset_index(), id_vars=inference_cols, value_vars=years, var_name=time_col, value_name='Emissions')\n",
    "        pred_yearly = train_yearly.groupby(inference_cols+[time_col]).mean()['Emissions'].reset_index()\n",
    "\n",
    "    test_cleared = test_yearly.dropna(subset=['Emissions'])\n",
    "    if len(test_cleared) > max_test_set:\n",
    "        test_cleared = test_cleared.sample(n=max_test_set, random_state=random_state)\n",
    "    preds_merged = test_cleared.merge(pred_yearly, how='left', on=inference_cols+[time_col]).dropna(subset=['Emissions_y'])\n",
    "    # test_cleared = test_yearly.dropna(subset=['Emissions'])\n",
    "    # if len(test_cleared) > max_test_set:\n",
    "    #     test_cleared = test_cleared.sample(n=max_test_set, random_state=random_state)\n",
    "    # preds_merged = test_cleared.merge(pred_yearly, how='left', on=inference_cols+[time_col]).dropna(subset=['Emissions_y'])\n",
    "\n",
    "    return preds_merged['Emissions_x'], preds_merged['Emissions_y']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## sklearn classifier training - Loop over names and model definitions\n",
    "\n",
    "regression = False\n",
    "\n",
    "names = ['linearLogisticRegression', 'linearSGDClassifier', 'linearSVC', 'linearPassiveAggressiveClassifier', 'KNeighboursClassifier', 'decisionTreeClassifier', 'naiveBayesClassifier', 'adaBoostClassifier', 'randomForestClassifier-n50', 'linearPerceptron', 'mlpClassifier']\n",
    "\n",
    "models = [lms.LogisticRegression(), lms.SGDClassifier(), svm.LinearSVC(), lms.PassiveAggressiveClassifier(), neighbors.KNeighborsClassifier(), tree.DecisionTreeClassifier(), GaussianNB(), ensemble.AdaBoostClassifier(), ensemble.RandomForestClassifier(n_estimators=50), lms.Perceptron(), skl_nn.MLPClassifier()]\n",
    "\n",
    "for model_name, model in zip(names, models):\n",
    "    print(model_name)\n",
    "    model_type = 'reg' if regression else 'clf'\n",
    "    model_file = model_path+model_type+'_'+model_name+'_l'+str(str(gap_filling_level))+'_'+date.today().strftime(\"%y%m%d\")\n",
    "\n",
    "    y_train, y_test = (y_train_clf, y_test_clf) if model_type == 'clf' else (y_train_reg, y_test_reg)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    joblib.dump(model, model_file+'.joblib')\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    scores = metrics(y_test, y_pred, model_type)\n",
    "\n",
    "    np.save(model_file+'.npy', scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def balance_classes(X_train, X_test, y_train, y_test, col_name = 'Emissions'):\n",
    "    min_count = y_train.reset_index().groupby(col_name).count().min()\n",
    "    y_train_df = y_train.reset_index(drop=True).groupby(col_name).sample(min_count.values)\n",
    "    y_train = y_train_df[col_name].values\n",
    "    X_train = X_train[y_train_df.index]\n",
    "\n",
    "    min_count_test = y_test.reset_index().groupby(col_name).count().min()\n",
    "    y_test_df = y_test.reset_index(drop=True).groupby(col_name).sample(min_count_test.values)\n",
    "    y_test = y_test_df[col_name].values\n",
    "    X_test = X_test[y_test_df.index]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "petrochemicals\n",
      "Gap level 1\n",
      "linearLogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearSGDClassifier\n",
      "linearSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearPassiveAggressiveClassifier\n",
      "KNeighboursClassifier\n",
      "decisionTreeClassifier\n",
      "naiveBayesClassifier\n",
      "adaBoostClassifier\n",
      "randomForestClassifier-n50\n",
      "Gap level 2\n",
      "linearLogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearSGDClassifier\n",
      "linearSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearPassiveAggressiveClassifier\n",
      "KNeighboursClassifier\n",
      "decisionTreeClassifier\n",
      "naiveBayesClassifier\n",
      "adaBoostClassifier\n",
      "randomForestClassifier-n50\n",
      "Gap level 3\n",
      "linearLogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearSGDClassifier\n",
      "linearSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearPassiveAggressiveClassifier\n",
      "KNeighboursClassifier\n",
      "decisionTreeClassifier\n",
      "naiveBayesClassifier\n",
      "adaBoostClassifier\n",
      "randomForestClassifier-n50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "### Training loop\n",
    "param_grids_orig = [\n",
    "    {  # Logistic Regression\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.01, 0.1, 1.0, 10.0],\n",
    "        'solver': ['saga'], #['liblinear', 'saga'],\n",
    "        'class_weight': ['balanced'] #[None, 'balanced']\n",
    "    },\n",
    "    {  # SGD Classifier\n",
    "        'loss': ['log', 'modified_huber'],#['hinge', 'log', 'modified_huber'],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'alpha': [0.001, 0.01],#[0.0001, 0.001, 0.01],\n",
    "        'class_weight': ['balanced']#[None, 'balanced']\n",
    "    },\n",
    "    {  # Linear SVC\n",
    "        'C': [1.0], # [0.1, 1.0, 10.0],\n",
    "        'loss': ['squared_hinge'],#['hinge', 'squared_hinge'],\n",
    "        'penalty': ['l2'], #['l1', 'l2']\n",
    "        'max_iter':[200]\n",
    "    },\n",
    "    {  # Passive Aggressive Classifier\n",
    "        'C': [0.1, 1.0, 10.0],\n",
    "        'loss': ['hinge', 'squared_hinge'],\n",
    "        #penalty': ['l1', 'l2'],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    {  # K Neighbors Classifier\n",
    "        'n_neighbors': [3, 5, 7],\n",
    "        'weights': ['uniform'],\n",
    "        'algorithm': ['kd_tree']\n",
    "    },\n",
    "    {  # Decision Tree Classifier\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None],#[None, 5, 10],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    {  # Gaussian Naive Bayes Classifier\n",
    "    },\n",
    "    {  # AdaBoost Classifier\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 1.0]\n",
    "    },\n",
    "    {  # Random Forest Classifier\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None], #[None, 5, 10],\n",
    "        'min_samples_split': [5,10]#[2, 5, 10]\n",
    "    },\n",
    "]\n",
    "\n",
    "## Inputs\n",
    "# Input data\n",
    "data_path = \"C:/Users\\lukec\\PycharmProjects\\emissions-tracking-conda\\emissions-tracking\\models/datasets/\"\n",
    "for input_data in ['petrochemicals']:\n",
    "    print(input_data)\n",
    "     # Output data\n",
    "    model_path = 'C:/Users\\lukec\\PycharmProjects\\emissions-tracking-conda\\emissions-tracking\\models/'+input_data+'/'\n",
    "    regression = False\n",
    "    gap_filling_level = [1,2,3]\n",
    "    balance = True\n",
    "    # Define divider for level 3\n",
    "    # if input_data == 'CT_manufacturing':\n",
    "    #     divider = 'iso3_country'\n",
    "    #     inference_cols = ['iso3_country', 'original_inventory_sector', 'asset_type']\n",
    "    #     time_col = 'Timestep'\n",
    "    #     timesteps = [str(i) for i in range(0,90)]\n",
    "    #     graph_cols, max_edges = [0,1,3,5], 100\n",
    "    #     gap_filling_level = [3]\n",
    "    # elif input_data == 'petrochemicals':\n",
    "    #     divider = 'COUNTRY/TERRITORY'\n",
    "    #     inference_cols = ['PRODUCT', 'COUNTRY/TERRITORY']\n",
    "    #     time_col = 'Year'\n",
    "    #     timesteps = [str(i) for i in range(1978,2051)]\n",
    "    #     graph_cols, max_edges = [0,3], 30\n",
    "    # elif input_data == 'unfccc':\n",
    "    #     divider='Party'\n",
    "    #     inference_cols = ['Party', 'Category']\n",
    "    #     time_col = 'Year'\n",
    "    #     timesteps = [str(i) for i in range(1990,2021)]\n",
    "    #     graph_cols, max_edges = [0], 100\n",
    "    #\n",
    "    # ## Parameters\n",
    "    # max_test_set = 100000\n",
    "    # random_state = 2\n",
    "    # test_size = 0.3\n",
    "    # regression = False\n",
    "\n",
    "    # data = pd.read_csv(data_path+input_data+'.csv')\n",
    "    # Gap level\n",
    "    for gap_filling_level in gap_filling_level:\n",
    "        print('Gap level '+str(gap_filling_level))\n",
    "        # feature_cols, train_yearly, test_yearly = create_yearly_data(data, input_data, gap_filling_level, timesteps, test_size)\n",
    "        # # Digitise train & test sets\n",
    "        # X_train_unscaled, X_test_unscaled, y_train_clf, y_test_clf, y_train_reg, y_test_reg, x_enc = preprocess_yearly(train_yearly, test_yearly)\n",
    "        #\n",
    "        # # Scale datasets & save as .npy\n",
    "        # scaler = pp.StandardScaler().fit(X_train_unscaled)\n",
    "        # X_train, X_test = scaler.transform(X_train_unscaled), scaler.transform(X_test_unscaled)\n",
    "\n",
    "        X_train = np.load(data_path+'X_train-'+input_data+'-'+str(gap_filling_level)+'.npy')\n",
    "        X_test = np.load(data_path+'X_test-'+input_data+'-'+str(gap_filling_level)+'.npy')\n",
    "        y_train_clf = pd.read_csv(data_path+'y_train-'+input_data+'-'+str(gap_filling_level)+'.csv', index_col=0)\n",
    "        y_test_clf = pd.read_csv(data_path+'y_test-'+input_data+'-'+str(gap_filling_level)+'.csv', index_col=0)\n",
    "\n",
    "        if balance:\n",
    "            X_train, X_test, y_train_clf, y_test_clf = balance_classes(X_train, X_test, y_train_clf, y_test_clf)\n",
    "\n",
    "        names = ['linearLogisticRegression', 'linearSGDClassifier', 'linearSVC', 'linearPassiveAggressiveClassifier', 'KNeighboursClassifier', 'decisionTreeClassifier', 'naiveBayesClassifier', 'adaBoostClassifier', 'randomForestClassifier-n50']\n",
    "        models = [lms.LogisticRegression(), lms.SGDClassifier(), svm.LinearSVC(), lms.PassiveAggressiveClassifier(), neighbors.KNeighborsClassifier(), tree.DecisionTreeClassifier(), GaussianNB(), ensemble.AdaBoostClassifier(), ensemble.RandomForestClassifier(n_estimators=50)]\n",
    "        param_grids = param_grids_orig\n",
    "\n",
    "        for model_name, model, param_grid in zip(names, models, param_grids):\n",
    "            print(model_name)\n",
    "            model_type = 'reg' if regression else 'clf'\n",
    "            model_file = model_path + model_type + '_' + model_name + '_l' + str(str(gap_filling_level)) + '_' + date.today().strftime(\"%y%m%d\")\n",
    "\n",
    "            y_train, y_test = (y_train_clf, y_test_clf) if model_type == 'clf' else (y_train_reg, y_test_reg)\n",
    "\n",
    "            # Perform grid search to find the best hyperparameters\n",
    "            grid_search = GridSearchCV(model, param_grid, scoring='accuracy', cv=5)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "\n",
    "            # Get the best model with optimized hyperparameters\n",
    "            best_model = grid_search.best_estimator_\n",
    "\n",
    "            # Train the best model on the training data\n",
    "            best_model.fit(X_train, y_train)\n",
    "\n",
    "            # Save the best model\n",
    "            #joblib.dump(best_model, model_file + '.joblib')\n",
    "\n",
    "            # Evaluate the best model on the testing data\n",
    "            y_pred = best_model.predict(X_test)\n",
    "\n",
    "            scores = metrics(y_test, y_pred, model_type)\n",
    "\n",
    "            np.save(model_file + '.npy', scores)\n",
    "\n",
    "            # Save the accuracies generated by each combination to a file\n",
    "            with open(model_file + '_accuracies.txt', 'w') as file:\n",
    "                file.write('Hyperparameters,Accuracy\\n')\n",
    "                for params, accuracy in zip(grid_search.cv_results_['params'], grid_search.cv_results_['mean_test_score']):\n",
    "                    file.write(str(params) + ',' + str(accuracy) + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CT_manufacturing\n",
      "Gap level 1\n",
      "KNeighboursClassifier\n",
      "decisionTreeClassifier\n",
      "naiveBayesClassifier\n",
      "adaBoostClassifier\n",
      "randomForestClassifier-n50\n",
      "Gap level 2\n",
      "linearLogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearSGDClassifier\n",
      "linearSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "80 fits failed out of a total of 160.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.50883322 0.50884367        nan 0.47457717\n",
      "        nan 0.50884367        nan        nan 0.50883845 0.50885413\n",
      "        nan 0.46696175        nan 0.50885413        nan        nan\n",
      " 0.50886981 0.50889071        nan 0.46144751        nan 0.50889071\n",
      "        nan        nan 0.50885935 0.50889071        nan 0.46635546\n",
      "        nan 0.50781402]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearPassiveAggressiveClassifier\n",
      "KNeighboursClassifier\n",
      "decisionTreeClassifier\n",
      "naiveBayesClassifier\n",
      "adaBoostClassifier\n",
      "randomForestClassifier-n50\n",
      "Gap level 3\n",
      "linearLogisticRegression\n",
      "linearSGDClassifier\n",
      "linearSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "### Training loop\n",
    "param_grids_orig = [\n",
    "    {  # Logistic Regression\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.01, 0.1, 1.0, 10.0],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    {  # SGD Classifier\n",
    "        'loss': ['hinge', 'log', 'modified_huber'],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    {  # Linear SVC\n",
    "        'C': [0.01, 0.1, 1.0, 10.0],\n",
    "        'loss': ['hinge', 'squared_hinge'],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'dual': [False, True]\n",
    "    },\n",
    "    {  # Passive Aggressive Classifier\n",
    "        'C': [0.1, 1.0, 10.0],\n",
    "        'loss': ['hinge', 'squared_hinge'],\n",
    "        #penalty': ['l1', 'l2'],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    {  # K Neighbors Classifier\n",
    "        'n_neighbors': [3, 5, 7],\n",
    "        'weights': ['uniform'],\n",
    "        'algorithm': ['kd_tree']\n",
    "    },\n",
    "    {  # Decision Tree Classifier\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None]#[None, 5, 10],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    {  # Gaussian Naive Bayes Classifier\n",
    "    },\n",
    "    {  # AdaBoost Classifier\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 1.0]\n",
    "    },\n",
    "    {  # Random Forest Classifier\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None], #[None, 5, 10],\n",
    "        'min_samples_split': [5,10]#[2, 5, 10]\n",
    "    },\n",
    "]\n",
    "\n",
    "## Inputs\n",
    "# Input data\n",
    "data_path = \"C:/Users\\lukec\\PycharmProjects\\emissions-tracking-conda\\emissions-tracking\\data\\classification_inputs/\"\n",
    "for input_data in ['CT_manufacturing','petrochemicals','unfccc']:\n",
    "    print(input_data)\n",
    "     # Output data\n",
    "    model_path = 'C:/Users\\lukec\\PycharmProjects\\emissions-tracking-conda\\emissions-tracking\\models/'+input_data+'/'\n",
    "\n",
    "    # Define divider for level 3\n",
    "    if input_data == 'CT_manufacturing':\n",
    "        divider = 'iso3_country'\n",
    "        inference_cols = ['iso3_country', 'original_inventory_sector', 'asset_type']\n",
    "        time_col = 'Timestep'\n",
    "        timesteps = [str(i) for i in range(0,90)]\n",
    "        graph_cols, max_edges = [0,1,3,5], 100\n",
    "    elif input_data == 'petrochemicals':\n",
    "        divider = 'COUNTRY/TERRITORY'\n",
    "        inference_cols = ['PRODUCT', 'COUNTRY/TERRITORY']\n",
    "        time_col = 'Year'\n",
    "        timesteps = [str(i) for i in range(1978,2051)]\n",
    "        graph_cols, max_edges = [0,3], 30\n",
    "    elif input_data == 'unfccc':\n",
    "        divider='Party'\n",
    "        inference_cols = ['Party', 'Category']\n",
    "        time_col = 'Year'\n",
    "        timesteps = [str(i) for i in range(1990,2021)]\n",
    "        graph_cols, max_edges = [0], 100\n",
    "\n",
    "    ## Parameters\n",
    "    max_test_set = 100000\n",
    "    random_state = 2\n",
    "    test_size = 0.3\n",
    "    regression = False\n",
    "\n",
    "    data = pd.read_csv(data_path+input_data+'.csv')\n",
    "    # Gap level\n",
    "    for gap_filling_level in [1,2,3]:\n",
    "        print('Gap level '+str(gap_filling_level))\n",
    "        feature_cols, train_yearly, test_yearly = create_yearly_data(data, input_data, gap_filling_level, timesteps, test_size)\n",
    "        # Digitise train & test sets\n",
    "        X_train_unscaled, X_test_unscaled, y_train_clf, y_test_clf, y_train_reg, y_test_reg, x_enc = preprocess_yearly(train_yearly, test_yearly)\n",
    "\n",
    "        # Scale datasets & save as .npy\n",
    "        scaler = pp.StandardScaler().fit(X_train_unscaled)\n",
    "        X_train, X_test = scaler.transform(X_train_unscaled), scaler.transform(X_test_unscaled)\n",
    "\n",
    "        if input_data == 'CT_manufacturing' and gap_filling_level==1:\n",
    "            names = ['KNeighboursClassifier', 'decisionTreeClassifier', 'naiveBayesClassifier', 'adaBoostClassifier', 'randomForestClassifier-n50']\n",
    "            models = [neighbors.KNeighborsClassifier(), tree.DecisionTreeClassifier(), GaussianNB(), ensemble.AdaBoostClassifier(), ensemble.RandomForestClassifier(n_estimators=50)]\n",
    "            param_grids = param_grids_orig[4:]\n",
    "        else:\n",
    "            names = ['linearLogisticRegression', 'linearSGDClassifier', 'linearSVC', 'linearPassiveAggressiveClassifier', 'KNeighboursClassifier', 'decisionTreeClassifier', 'naiveBayesClassifier', 'adaBoostClassifier', 'randomForestClassifier-n50']\n",
    "            models = [lms.LogisticRegression(), lms.SGDClassifier(), svm.LinearSVC(), lms.PassiveAggressiveClassifier(), neighbors.KNeighborsClassifier(), tree.DecisionTreeClassifier(), GaussianNB(), ensemble.AdaBoostClassifier(), ensemble.RandomForestClassifier(n_estimators=50)]\n",
    "            param_grids = param_grids_orig\n",
    "\n",
    "        for model_name, model, param_grid in zip(names, models, param_grids):\n",
    "            print(model_name)\n",
    "            model_type = 'reg' if regression else 'clf'\n",
    "            model_file = model_path + model_type + '_' + model_name + '_l' + str(str(gap_filling_level)) + '_' + date.today().strftime(\"%y%m%d\")\n",
    "\n",
    "            y_train, y_test = (y_train_clf, y_test_clf) if model_type == 'clf' else (y_train_reg, y_test_reg)\n",
    "\n",
    "            # Perform grid search to find the best hyperparameters\n",
    "            grid_search = GridSearchCV(model, param_grid, scoring='accuracy' if model_type == 'clf' else 'neg_mean_squared_error', cv=5)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "\n",
    "            # Get the best model with optimized hyperparameters\n",
    "            best_model = grid_search.best_estimator_\n",
    "\n",
    "            # Train the best model on the training data\n",
    "            best_model.fit(X_train, y_train)\n",
    "\n",
    "            # Save the best model\n",
    "            #joblib.dump(best_model, model_file + '.joblib')\n",
    "\n",
    "            # Evaluate the best model on the testing data\n",
    "            y_pred = best_model.predict(X_test)\n",
    "\n",
    "            scores = metrics(y_test, y_pred, model_type)\n",
    "\n",
    "            np.save(model_file + '.npy', scores)\n",
    "\n",
    "            # Save the accuracies generated by each combination to a file\n",
    "            with open(model_file + '_accuracies.txt', 'w') as file:\n",
    "                file.write('Hyperparameters,Accuracy\\n')\n",
    "                for params, accuracy in zip(grid_search.cv_results_['params'], grid_search.cv_results_['mean_test_score']):\n",
    "                    file.write(str(params) + ',' + str(accuracy) + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}